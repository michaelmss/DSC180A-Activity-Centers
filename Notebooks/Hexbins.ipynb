{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "from shapely.wkt import loads\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data and Organize Columns, and remove bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"../data/SANGIS/BUSINESS_SITES/BUSINESS_SITES.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[gdf['POINT_X']!=0]\n",
    "gdf['x'] = gdf['geometry'].x\n",
    "gdf['y'] = gdf['geometry'].y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Hexbins\n",
    "(note - gridsize was manually calculated based on width of SD County to generate roughly 1/4 mile radius hexbins:\n",
    "SD County is roughly 86 miles east to west, and the grid size takes the quantity of hexbins by width\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexes = matplotlib.pyplot.hexbin( x= gdf['x'], y=gdf['y'],mincnt=1,gridsize=86*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexbins = gpd.points_from_xy(x=[i[0] for i in hexes.get_offsets()],y=[i[1] for i in hexes.get_offsets()])[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the data with the newly generated hexbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merge = gpd.GeoDataFrame(hexbins, geometry=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merge = gpd.sjoin_nearest(left_merge,gdf,how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the # of datapoints in each hexbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_and_counts = full_merge.groupby('index_left').count().sort_values(by='x').reset_index()[['index_left','APN',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(index):\n",
    "    return hexbins[index].x\n",
    "def get_y(index):\n",
    "    return hexbins[index].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_and_counts['x'] = index_and_counts['index_left'].apply(get_x)\n",
    "index_and_counts['y'] = index_and_counts['index_left'].apply(get_y)\n",
    "index_and_counts['geometry'] = gpd.points_from_xy(index_and_counts['x'], index_and_counts['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.GeoDataFrame(index_and_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(column='APN', markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering techniques - use maxima as cluster centers and run kmeans for distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea 1 - could we use 70 biggest maxima as centers?\n",
    "df['is_center'] = df['APN']>=df['APN'].sort_values(ascending=False).reset_index(drop=True)[70]\n",
    "df.plot(column='is_center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering based off local maxima centers using kmeans\n",
    "cluster_centers = df[df['is_center']==True][['x', 'y']].values\n",
    "other_points = df[['x', 'y']].values\n",
    "k = len(cluster_centers)\n",
    "kmeans = KMeans(n_clusters=k, init=cluster_centers, n_init=1)\n",
    "kmeans.fit(other_points)\n",
    "df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: have at least 5 hexbins per cluster?/count of businesses per cluster?\n",
    "df.plot(column='cluster', legend=True, markersize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference from just clustering on distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other idea - what does python have available? \n",
    "# basic dbscan clustering on distance\n",
    "scaler = StandardScaler()\n",
    "df['scaled_weight'] = scaler.fit_transform(df[['APN']])\n",
    "features = df[['x', 'y','APN']]\n",
    "dbscan = DBSCAN(eps=6000, min_samples=20)\n",
    "df['cluster_label'] = dbscan.fit_predict(features)\n",
    "df.plot(column='cluster_label', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other idea - db scan but for just the counts to find local maxima?\n",
    "scaler = StandardScaler()\n",
    "df['scaled_weight'] = scaler.fit_transform(df[['APN']])\n",
    "features = df[['APN']]\n",
    "dbscan = DBSCAN(eps=1, min_samples=1)\n",
    "df['cluster_label'] = dbscan.fit_predict(features)\n",
    "df.plot(column='cluster_label', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Polygons from local maxima approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: potentially consolidate with block groups on intersects with hexbins\n",
    "poly_df = full_merge.merge(df[['index_left','cluster']],how='left')\n",
    "\n",
    "geometry = poly_df['geometry'].apply(Point)\n",
    "gpdf = gpd.GeoDataFrame(poly_df, geometry=geometry)\n",
    "\n",
    "grouped = gpdf.groupby('cluster')\n",
    "\n",
    "polygons = []\n",
    "for cluster, group in grouped:\n",
    "    polygon = group['geometry'].unary_union.convex_hull\n",
    "    polygons.append({'cluster': cluster, 'geometry': polygon})\n",
    "\n",
    "polygons_gdf = gpd.GeoDataFrame(polygons)\n",
    "\n",
    "polygons_gdf.plot(column='cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group['geometry'].unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = gpd.read_file('../data/Census_Blocks_20231127.csv').drop(columns=['geometry'])\n",
    "blocks['the_geom'] = blocks['the_geom'].apply(loads)\n",
    "blocks = blocks.set_geometry('the_geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['BUSTYPE'].str.contains('HOS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "461/98162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dt_employment_center",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
